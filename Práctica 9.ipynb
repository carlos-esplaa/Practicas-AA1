{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c8715f",
   "metadata": {},
   "source": [
    "# Práctica 9: Clasificador Bayesiano.\n",
    "\n",
    "- Grupo 1:\n",
    "    - Jesús María Matos Torres.\n",
    "    - Carlos Santana Esplá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbdb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa2599",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Clasificación de mensajes como spam con Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db12054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el clasificador GaussianNB() obtenemos para el conjunto de datos binarios una tasa de acierto de 0.6985645933014354 y para el conjunto de datos real 0.7416267942583732\n",
      "Sus matrices de confusión serán respectivamente:\n",
      "[[963 494]\n",
      " [ 10 205]]\n",
      "[[1010  423]\n",
      " [   9  230]]\n",
      "Para el clasificador MultinomialNB() obtenemos para el conjunto de datos binarios una tasa de acierto de 0.9766746411483254 y para el conjunto de datos real 0.9683014354066986\n",
      "Sus matrices de confusión serán respectivamente:\n",
      "[[1442   15]\n",
      " [  24  191]]\n",
      "[[1429    4]\n",
      " [  49  190]]\n",
      "Para el clasificador ComplementNB() obtenemos para el conjunto de datos binarios una tasa de acierto de 0.9497607655502392 y para el conjunto de datos real 0.944377990430622\n",
      "Sus matrices de confusión serán respectivamente:\n",
      "[[1389   68]\n",
      " [  16  199]]\n",
      "[[1352   81]\n",
      " [  12  227]]\n",
      "Para el clasificador BernoulliNB() obtenemos para el conjunto de datos binarios una tasa de acierto de 0.9772727272727273 y para el conjunto de datos real 0.9772727272727273\n",
      "Sus matrices de confusión serán respectivamente:\n",
      "[[1448    9]\n",
      " [  29  186]]\n",
      "[[1423   10]\n",
      " [  28  211]]\n"
     ]
    }
   ],
   "source": [
    "df_bin = pd.read_csv('./datos practicas/Aprendizaje-Automatico-I-main/Práctica 9/spam_preprocesado_binario.csv')\n",
    "df_real = pd.read_csv('./datos practicas/Aprendizaje-Automatico-I-main/Práctica 9/spam_preprocesado_reales.csv')\n",
    "\n",
    "x_bin = df_bin.iloc[:,1:]\n",
    "y_bin = df_bin.iloc[:,0]\n",
    "\n",
    "x_real = df_real.iloc[:,1:]\n",
    "y_real = df_real.iloc[:,0]\n",
    "\n",
    "        xb_train, xb_test, yb_train, yb_test = train_test_split(x_bin, y_bin, test_size=0.3, train_size=0.7)\n",
    "xr_train, xr_test, yr_train, yr_test = train_test_split(x_real, y_real, test_size=0.3, train_size=0.7)\n",
    "\n",
    "nb = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]\n",
    "\n",
    "for i in range(len(nb)):\n",
    "    clf = nb[i]\n",
    "    yb_pred = clf.fit(xb_train, yb_train).predict(xb_test)\n",
    "    scoreb = accuracy_score(yb_pred, yb_test)\n",
    "    \n",
    "    yr_pred = clf.fit(xr_train, yr_train).predict(xr_test)\n",
    "    scorer = accuracy_score(yr_pred, yr_test)\n",
    "    \n",
    "    print('Para el clasificador', nb[i], 'obtenemos para el conjunto de datos binarios una tasa de acierto de', scoreb,\n",
    "         'y para el conjunto de datos real', scorer)\n",
    "    print('Sus matrices de confusión serán respectivamente:')\n",
    "    print(confusion_matrix(yb_test, yb_pred))\n",
    "    print(confusion_matrix(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ee425",
   "metadata": {},
   "source": [
    "- Tras varias iteraciones, determinamos lo siguiente de cada clasificador:\n",
    "    \n",
    "    - GaussianNB: Este clasificador suele ser usado para datos cuya verosimilitud sigue una distribición normal, para este ejercicio, nos da una mejor precisión con el conjunto de datos reales que para el conjunto de datos binario con una diferencia de entre 2% y 5%.\n",
    "    \n",
    "    - MultinomialNB: el uso de este clasificador es para analizar la cantidad de apariciones de un valor o una palabra, por lo que suele funcionar mejor para datos reales, para nuestro ejercicio esta hipótesis no se corrobora, ya que el accuracy_score de los datos reales es menor que el de los datos binario siendo una diferencia muy pequeña después de varias iteraciones.\n",
    "    \n",
    "    - ComplementNB: sin embargo, el clasificador complementNB, está relacionado con el anterior, su diferencia es que en este caso las clases están desbalanceadas, es decir, no hay la misma cantidad de datos para cada clase, por lo que los datos reales como en el anterior, deberían tener una mejor precisión, sin embargo esto no es así, aunque la diferencia entre las precisiones de ambos conjuntos de datos es ínfima.\n",
    "    \n",
    "    - BernoulliNB: suele ser útil para características booleanas, por ende, la precisión de los datos binarios debería ser bastante mejor. A pesar de esto, aunque vemos como la percisión de los datos binarios es mejor, la diferencia es muy pequeña. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aed276",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Comparación de clasificación de mensajes spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8827020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Clasificador  Conjunto Binario  Conjunto Real\n",
      "          Perceptron()          0.969498       0.974282\n",
      "  LogisticRegression()          0.977871       0.966507\n",
      "                 SVC()          0.980263       0.978469\n",
      "KNeighborsClassifier()          0.937201       0.923445\n"
     ]
    }
   ],
   "source": [
    "clasif = [Perceptron(), LogisticRegression(), SVC(), KNeighborsClassifier()]\n",
    "tabla = []\n",
    "\n",
    "for i in range(len(clasif)):\n",
    "    tabla2 = []\n",
    "    tabla2.append(clasif[i])\n",
    "    \n",
    "    clf = clasif[i]\n",
    "    yb_pred = clf.fit(xb_train, yb_train).predict(xb_test)\n",
    "    tabla2.append(accuracy_score(yb_pred, yb_test))\n",
    "    \n",
    "    yr_pred = clf.fit(xr_train, yr_train).predict(xr_test)\n",
    "    tabla2.append(accuracy_score(yr_pred, yr_test))\n",
    "    \n",
    "    tabla.append(tabla2)\n",
    "\n",
    "df = pd.DataFrame(tabla, columns=['Clasificador', 'Conjunto Binario', 'Conjunto Real'])\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cfb702",
   "metadata": {},
   "source": [
    "- Ahora analizaremos los clasificadores usados en las otras prácticas:\n",
    "    \n",
    "    - Perceptrón: sabiendo que la clasificación por perceptron funciona mejor con datos binarios, observamos como para nuestro ejercicio, esto no se corrobora, ya que la presición de los datos reales, es mayor que la de los datos binarios, como vemos en la tabla.\n",
    "    \n",
    "    - Regresión logística: partiendo de la base que la regresión logística se puede utilizar para ambos conjuntos de datos, aunque se adapta mejor a los datos binarios como se puede analizar en la solución del ejercicio, teniendo un accuracy_score mayor en ese conjunto de datos (binario). \n",
    "    \n",
    "    - SVC: este clasificador también tiene buena aceptación en ambos conjunto de datos y también se corrobora con el ejercicio, ya que la diferencia entre ambas tasas de acierto es bastante pequeña. Además, este es el clasificador con mejor precisión.\n",
    "    \n",
    "    - Vecino más cercano: teniendo en cuenta, que el clasificador de vecino más cercano, como el clasificador anterior, funciona para ambos conjuntos de datos, nos sorprende que la diferencia entre la precisión de los diferentes conjuntos de datos, es mayor de lo esperado, ciertamente, esta diferencia no es elevada, tampoco es tan cercana como el clasificador SVC, que sería lo esperado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
